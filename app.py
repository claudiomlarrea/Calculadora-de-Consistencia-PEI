import io
import re
import unicodedata
from typing import Optional, List, Dict, Tuple
import numpy as np
import pandas as pd
import streamlit as st
from rapidfuzz import fuzz
from docx import Document

# ===========================
# Utilidades y configuraci√≥n
# ===========================
SPANISH_STOPWORDS = {
    "a","ante","bajo","cabe","con","contra","de","desde","durante","en","entre","hacia","hasta","mediante",
    "para","por","seg√∫n","sin","so","sobre","tras","el","la","los","las","un","una","unos","unas","y","o","u","e","ni","que",
    "como","al","del","se","su","sus","es","son","ser","estar","esta","este","estos","estas","hay","m√°s","menos","muy","ya",
    "no","s√≠","si","pero","porque","cuando","donde","cada","lo","le","les","tambi√©n","adem√°s"
}
BLANK_TOKENS = {
    "", "nan", "none", "s d", "sd", "s n d", "s n/d", "n a", "n/a",
    "no corresponde", "no aplica", "ninguno", "0", "-", "‚Äì", "‚Äî", "‚úì"
}
CODE_RE = re.compile(r"\d+(?:\.\d+)+")  # ej. 1.4, 1.5.2

def is_blank(x) -> bool:
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return True
    return str(x).strip().lower() in BLANK_TOKENS

def to_clean_str_series(s: pd.Series) -> pd.Series:
    return s.fillna("").astype(str)

def strip_accents(s: str) -> str:
    return "".join(c for c in unicodedata.normalize("NFD", s) if unicodedata.category(c) != "Mn")

def tokens_clean(s: str) -> List[str]:
    s = s.lower()
    s = re.sub(r"[^a-z0-9√°√©√≠√≥√∫√º√±\s\.]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return [t for t in s.split() if t not in SPANISH_STOPWORDS]

def jaccard(a: List[str], b: List[str]) -> float:
    sa, sb = set(a), set(b)
    if not sa and not sb:
        return 0.0
    return len(sa & sb) / max(1, len(sa | sb))

def combined_score(activity: str, objective: str) -> float:
    t_ratio = fuzz.token_set_ratio(activity, objective) / 100.0
    jac = jaccard(tokens_clean(activity), tokens_clean(objective))
    return float(0.6 * t_ratio + 0.4 * jac)

def force_goal_only(text: str) -> str:
    """
    Devuelve exclusivamente el tramo '1.x ‚Ä¶' del objetivo.
    Si no hay c√≥digo, devuelve el texto original.
    """
    s = str(text).strip()
    m = CODE_RE.search(s)
    if not m:
        return s
    tail = s[m.start():]
    tail = re.sub(r"\s*[-‚Äì‚Äî]\s*", " ", tail).strip()
    return tail

def parse_top_objective_from_name(name: str) -> Optional[str]:
    m = re.search(r"[Oo]bjetivo\s*(\d+)", name)
    return f"Objetivo {m.group(1)}" if m else None

# Duplicados: normalizaci√≥n simple
def normalize_for_dupes(s: str) -> str:
    s = strip_accents(s.lower())
    s = re.sub(r"[^a-z0-9\s]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

# ===========================
# Detecci√≥n de columnas
# ===========================
def best_column(df: pd.DataFrame, candidates) -> Optional[str]:
    best, best_score = None, -1
    for col in df.columns:
        col_norm = col.strip().lower()
        for cand in candidates:
            s = fuzz.partial_ratio(col_norm, cand.strip().lower())
            if s > best_score:
                best, best_score = col, s
    return best

def guess_columns(df: pd.DataFrame) -> Tuple[Optional[str], Optional[str]]:
    col_obj = best_column(df, [
        "objetivo especifico", "objetivo espec√≠fico", "objetivos especificos", "objetivos espec√≠ficos",
        "objetivo", "objetivo pei", "objetivo del pei"
    ])
    col_act = best_column(df, [
        "actividad", "actividades", "acciones", "actividad espec√≠fica", "actividad especifica",
        "descripcion de la actividad", "descripci√≥n de la actividad"
    ])
    return col_obj, col_act

# ===========================
# Carga de archivos (CSV/XLSX)
# ===========================
def load_frames_from_upload(uploaded_file) -> List[pd.DataFrame]:
    """Devuelve una lista de DataFrames (una por archivo/hoja √∫til)."""
    frames = []
    name = getattr(uploaded_file, "name", "archivo")
    try:
        if name.lower().endswith(".csv"):
            df = pd.read_csv(uploaded_file)
            frames.append(df)
        else:
            xls = pd.ExcelFile(uploaded_file)
            # Elegir la hoja "m√°s prometedora"
            best_sheet, best_hit = None, -1
            for sh in xls.sheet_names:
                tmp = pd.read_excel(xls, sheet_name=sh)
                col_obj, col_act = guess_columns(tmp)
                hit = int(col_obj is not None) + int(col_act is not None)
                if hit > best_hit:
                    best_hit, best_sheet = hit, sh
            if best_sheet is None:
                best_sheet = xls.sheet_names[0]
            frames.append(pd.read_excel(xls, sheet_name=best_sheet))
    except Exception:
        frames.append(pd.read_excel(uploaded_file))
    return frames

# ===========================
# Evaluaci√≥n por DataFrame
# ===========================
def evaluate_df(df: pd.DataFrame, top_obj_label: Optional[str]) -> pd.DataFrame:
    col_obj, col_act = guess_columns(df)
    if not col_obj or not col_act:
        return pd.DataFrame(columns=[
            "Objetivo espec√≠fico","Actividad","Porcentaje de consistencia","Fuente (archivo)"
        ])

    objetivo = to_clean_str_series(df[col_obj]).apply(force_goal_only)
    actividad = to_clean_str_series(df[col_act])

    work = pd.DataFrame({
        "_objetivo": objetivo,
        "_actividad": actividad
    })

    # Excluir objetivos vac√≠os
    vacio_obj = work["_objetivo"].apply(is_blank)
    work.loc[vacio_obj, "_objetivo"] = "Sin objetivo (vac√≠o)"
    work = work[work["_objetivo"] != "Sin objetivo (vac√≠o)"].copy()

    # Score
    work["Porcentaje de consistencia"] = work.apply(
        lambda r: round(combined_score(r["_actividad"], r["_objetivo"]) * 100.0, 1), axis=1
    )

    out = work.rename(columns={"_objetivo":"Objetivo espec√≠fico","_actividad":"Actividad"})
    out["Fuente (archivo)"] = top_obj_label or ""
    return out[["Objetivo espec√≠fico","Actividad","Porcentaje de consistencia","Fuente (archivo)"]]

# ===========================
# Sugerencia de objetivo √≥ptimo
# ===========================
def suggest_objective_for_activity(activity: str, candidates: List[str]) -> Tuple[str, float]:
    if is_blank(activity) or not candidates:
        return ("", 0.0)
    best_obj, best_score = "", -1.0
    for obj in candidates:
        s = combined_score(activity, obj) * 100.0
        if s > best_score:
            best_score = s
            best_obj = obj
    return (best_obj, round(float(best_score), 1))

# ===========================
# Informe Word avanzado (v9)
# ===========================
def add_table(doc: Document, headers: List[str], rows: List[List[str]]):
    t = doc.add_table(rows=1, cols=len(headers))
    t.style = "Light List Accent 1"
    hdr = t.rows[0].cells
    for j, h in enumerate(headers):
        hdr[j].text = str(h)
    for row in rows:
        cells = t.add_row().cells
        for j, val in enumerate(row):
            cells[j].text = str(val)

def build_word_report(final: pd.DataFrame, n_archivos: int) -> bytes:
    doc = Document()
    doc.add_heading("Conclusiones de Consistencia de actividades ‚Äì Informe avanzado", 0)

    # ------------------ M√©tricas globales ------------------
    n = len(final)
    mean = round(float(final["Porcentaje de consistencia"].mean()), 1) if n else 0.0
    median = round(float(final["Porcentaje de consistencia"].median()), 1) if n else 0.0
    p25 = round(float(final["Porcentaje de consistencia"].quantile(0.25)), 1) if n else 0.0
    p75 = round(float(final["Porcentaje de consistencia"].quantile(0.75)), 1) if n else 0.0
    vmin = round(float(final["Porcentaje de consistencia"].min()), 1) if n else 0.0
    vmax = round(float(final["Porcentaje de consistencia"].max()), 1) if n else 0.0

    doc.add_paragraph(f"Archivos procesados: {n_archivos}")
    doc.add_paragraph(f"Cantidad de actividades evaluadas: {n}")
    doc.add_paragraph(f"Porcentaje promedio de consistencia general: {mean:.1f}%")
    doc.add_paragraph(f"Mediana: {median:.1f}% | P25: {p25:.1f}% | P75: {p75:.1f}% | M√≠n/M√°x: {vmin:.1f}% / {vmax:.1f}%")

    # Niveles
    alta = int((final["Porcentaje de consistencia"] >= 75).sum())
    media = int(((final["Porcentaje de consistencia"] >= 50) & (final["Porcentaje de consistencia"] < 75)).sum())
    baja  = int((final["Porcentaje de consistencia"] < 50).sum())

    doc.add_heading("Distribuci√≥n por niveles", level=1)
    add_table(doc, ["Nivel","N actividades"], [
        ["Alta (>=75%)", alta],
        ["Media (50‚Äì74%)", media],
        ["Baja (<50%)", baja]
    ])
    doc.add_paragraph(
        "Interpretaci√≥n: una mayor proporci√≥n en niveles Medio/Alto sugiere redacciones alineadas con los verbos, √°mbitos y productos de los objetivos. "
        "Una concentraci√≥n en Bajo indica redacciones gen√©ricas u objetivos poco acotados."
    )

    # ------------------ Ranking por Objetivo espec√≠fico ------------------
    doc.add_heading("Rendimiento por Objetivo espec√≠fico (Top 10 cr√≠ticos)", level=1)
    grp = final.groupby("Objetivo espec√≠fico").agg(
        n=("Actividad","count"),
        mean=("Porcentaje de consistencia","mean"),
        median=("Porcentaje de consistencia","median"),
        bajo=("Porcentaje de consistencia", lambda s: (s < 50).mean()*100.0)
    ).reset_index()
    grp["mean"] = grp["mean"].round(1)
    grp["median"] = grp["median"].round(1)
    grp["bajo"] = grp["bajo"].round(1)
    worst = grp.sort_values(["mean","bajo","n"], ascending=[True, False, False]).head(10)
    rows = [[r["Objetivo espec√≠fico"], int(r["n"]), f'{r["mean"]:.1f}%', f'{r["median"]:.1f}%', f'{r["bajo"]:.1f}%'] for _, r in worst.iterrows()]
    add_table(doc, ["Objetivo espec√≠fico","N","Promedio","Mediana","% en Bajo"], rows)
    doc.add_paragraph(
        "Estos objetivos requieren priorizaci√≥n para revisar definiciones, ajustar verbos/resultados esperados y asegurar la trazabilidad con actividades."
    )

    # ------------------ Objetivos con mayor dispersi√≥n ------------------
    doc.add_heading("Objetivos con mayor dispersi√≥n interna", level=1)
    disp = final.groupby("Objetivo espec√≠fico")["Porcentaje de consistencia"].agg(
        std=lambda s: float(np.std(s, ddof=0)),
        iqr=lambda s: float(s.quantile(0.75) - s.quantile(0.25)),
        n="count"
    ).reset_index()
    disp["std"] = disp["std"].round(1)
    disp["iqr"] = disp["iqr"].round(1)
    disp = disp.sort_values(["iqr","std"], ascending=False).head(8)
    rows = [[r["Objetivo espec√≠fico"], int(r["n"]), f'{r["std"]:.1f}', f'{r["iqr"]:.1f}'] for _, r in disp.iterrows()]
    add_table(doc, ["Objetivo espec√≠fico","N","Desv√≠o est√°ndar","IQR"], rows)
    doc.add_paragraph(
        "Alta dispersi√≥n sugiere criterios heterog√©neos o actividades redactadas con niveles de especificidad muy dispares."
    )

    # ------------------ Actividades con alto potencial de mejora ------------------
    doc.add_heading("Actividades con alto potencial de mejora/reubicaci√≥n", level=1)
    # Se consideran candidatas: actual <50% y mejora sugerida (delta) >= 15 p.p., si existen columnas de sugerencia
    cols_needed = {"Objetivo sugerido (m√°xima consistencia)","Porcentaje de consistencia (sugerido)","Diferencia (p.p.)"}
    if cols_needed.issubset(set(final.columns)):
        cand = final[(final["Porcentaje de consistencia"] < 50) & (final["Diferencia (p.p.)"] >= 15)].copy()
        cand = cand.sort_values(["Diferencia (p.p.)","Porcentaje de consistencia"], ascending=[False, True]).head(20)
        rows = [
            [
                r["Actividad"],
                r["Objetivo espec√≠fico"],
                f'{float(r["Porcentaje de consistencia"]):.1f}%',
                r["Objetivo sugerido (m√°xima consistencia)"],
                f'{float(r["Porcentaje de consistencia (sugerido)"]):.1f}%',
                f'{float(r["Diferencia (p.p.)"]):.1f}'
            ]
            for _, r in cand.iterrows()
        ]
        add_table(doc, ["Actividad","Obj. actual","% actual","Obj. sugerido","% sugerido","Œî p.p."], rows)
        doc.add_paragraph(
            "Nota: la reubicaci√≥n debe considerarse luego de **reelaborar la redacci√≥n** de la actividad. "
            "Si, tras la reescritura, la diferencia permanece alta y coherente con indicadores, reci√©n ah√≠ conviene moverla."
        )
    else:
        doc.add_paragraph("No se incluyeron columnas de sugerencia en el an√°lisis actual; omitiendo esta secci√≥n.")

    # ------------------ Duplicadas/similares ------------------
    doc.add_heading("Actividades duplicadas o muy similares (indicio)", level=1)
    norm = final["Actividad"].astype(str).apply(normalize_for_dupes)
    dupemap = norm.value_counts()
    dups = dupemap[dupemap >= 2].head(10)
    if len(dups) == 0:
        doc.add_paragraph("No se detectaron duplicidades evidentes por normalizaci√≥n simple.")
    else:
        rows = [[k, int(v)] for k, v in dups.items()]
        add_table(doc, ["Actividad (normalizada)","Repeticiones"], rows)
        doc.add_paragraph(
            "Sugerencia: consolidar duplicadas como **l√≠neas de trabajo** con sub-tareas medibles; "
            "evita dispersi√≥n y mejora la trazabilidad del PEI."
        )

    # ------------------ Recomendaciones y plan ------------------
    doc.add_heading("Gu√≠a pr√°ctica de reescritura", level=1)
    doc.add_paragraph("Plantilla sugerida: Verbo operativo + Objeto + √Åmbito/Poblaci√≥n + Entregable + Resultado esperado.")
    for ejemplo in [
        "Capacitar a 50 docentes de grado en evaluaci√≥n por competencias (5 talleres, Q2) ‚Üí Docentes formados y plan de aplicaci√≥n.",
        "Implementar tablero de seguimiento en Looker Studio para objetivos 1.x (actualizaci√≥n mensual) ‚Üí Indicadores disponibles y monitoreados.",
        "Dise√±ar e institucionalizar protocolo de autoevaluaci√≥n anual (versi√≥n 1.0, Q3) ‚Üí Informe de autoevaluaci√≥n y plan de mejora."
    ]:
        doc.add_paragraph("‚Ä¢ " + ejemplo)

    doc.add_heading("Plan de mejora por etapas", level=1)
    for item in [
        "Corto plazo (0‚Äì30 d√≠as): higiene de redacci√≥n, plantillas y glosario de verbos/entregables.",
        "Mediano plazo (1‚Äì3 meses): reencuadre de objetivos ambiguos, consolidaci√≥n de duplicadas y trazabilidad KPI/evidencias.",
        "Revisi√≥n trimestral/semestral: correr calculadora, identificar ‚ÄòBaja‚Äô, reelaborar y volver a medir; gobernanza a trav√©s de un comit√© PEI."
    ]:
        doc.add_paragraph("‚Ä¢ " + item)

    # ------------------ Anexo metodol√≥gico ------------------
    doc.add_heading("Anexo metodol√≥gico (s√≠ntesis)", level=1)
    doc.add_paragraph(
        "La consistencia se estima combinando similitud l√©xica (Token Set Ratio, 60%) y solapamiento de t√©rminos (Jaccard, 40%). "
        "Se limpia el ‚ÄòObjetivo espec√≠fico‚Äô para mantener solo el tramo ‚Äò1.x ‚Ä¶‚Äô, evitando mezclar con actividades o resultados."
    )

    buf = io.BytesIO(); doc.save(buf); buf.seek(0)
    return buf.getvalue()

# ===========================
# UI
# ===========================
st.set_page_config(page_title="An√°lisis de consistencia ‚Äì Multi-archivo (v9)", layout="wide")
st.title("üìä An√°lisis de consistencia de actividades PEI ‚Äì Multi-archivo (v9)")
st.caption("Acepta hasta 6 planillas (CSV/XLSX), limpia el objetivo (solo '1.x ‚Ä¶'), excluye 'Sin objetivo (vac√≠o)'; sugiere objetivo √≥ptimo y genera **informe Word avanzado**.")

uploads = st.file_uploader(
    "Sub√≠ las planillas (p. ej.: 'Plan Estrat√©gico ... Objetivo 1_Tabla.csv' ... 'Objetivo 6_Tabla.csv')",
    type=["csv","xlsx","xls"],
    accept_multiple_files=True
)

if uploads:
    st.write(f"Archivos cargados: **{len(uploads)}**")
    resultados = []
    detalle_archivos = []
    for f in uploads:
        label = parse_top_objective_from_name(getattr(f, "name", ""))
        frames = load_frames_from_upload(f)
        used = 0
        for df in frames:
            out = evaluate_df(df, label)
            if len(out):
                resultados.append(out)
                used += 1
        detalle_archivos.append((getattr(f, "name", "archivo"), label or "", used))

    if not resultados:
        st.warning("No se detectaron columnas de Objetivo/Actividad en los archivos cargados.")
    else:
        final = pd.concat(resultados, ignore_index=True)

        # -------- Sugerir objetivo √≥ptimo por actividad --------
        candidatos = sorted(pd.Series(final["Objetivo espec√≠fico"].unique()).dropna().tolist())
        sugeridos, sugeridos_pct, delta_pp = [], [], []
        for _, r in final.iterrows():
            best_obj, best_pct = suggest_objective_for_activity(r["Actividad"], candidatos)
            sugeridos.append(best_obj)
            sugeridos_pct.append(best_pct)
            delta_pp.append(round(best_pct - float(r["Porcentaje de consistencia"]), 1))
        final["Objetivo sugerido (m√°xima consistencia)"] = sugeridos
        final["Porcentaje de consistencia (sugerido)"] = sugeridos_pct
        final["Diferencia (p.p.)"] = delta_pp

        # -------- M√©tricas globales --------
        promedio = round(float(final["Porcentaje de consistencia"].mean()), 1) if len(final) else 0.0

        st.success(f"Se consolidaron **{len(final)}** actividades. Promedio global: **{promedio:.1f}%**.")
        st.dataframe(final.head(100))

        # -------- Excel: dos hojas --------
        informe = final[[
            "Objetivo espec√≠fico","Actividad",
            "Porcentaje de consistencia",
            "Objetivo sugerido (m√°xima consistencia)",
            "Porcentaje de consistencia (sugerido)",
            "Diferencia (p.p.)"
        ]].copy()
        informe["Porcentaje de consistencia total promedio"] = promedio

        informe_fuente = final[[
            "Fuente (archivo)","Objetivo espec√≠fico","Actividad",
            "Porcentaje de consistencia",
            "Objetivo sugerido (m√°xima consistencia)",
            "Porcentaje de consistencia (sugerido)",
            "Diferencia (p.p.)"
        ]].copy()

        buf_xlsx = io.BytesIO()
        with pd.ExcelWriter(buf_xlsx, engine="openpyxl") as w:
            informe.to_excel(w, index=False, sheet_name="Informe")
            informe_fuente.to_excel(w, index=False, sheet_name="Informe+Fuente")
        st.download_button("‚¨áÔ∏è Descargar Excel (consolidado)", data=buf_xlsx.getvalue(),
                           file_name="informe_consistencia_pei_consolidado.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

        # -------- Word avanzado --------
        word_bytes = build_word_report(final, n_archivos=len(uploads))
        st.download_button("‚¨áÔ∏è Descargar Word (Informe avanzado)", data=word_bytes,
                           file_name="conclusiones_consistencia_actividades_avanzado.docx",
                           mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document")

        # -------- Tabla de archivos procesados --------
        st.subheader("Archivos procesados")
        st.table(pd.DataFrame(detalle_archivos, columns=["Archivo","Etiqueta detectada","Hojas utilizadas"]))
else:
    st.info("Carg√° entre 1 y 6 archivos (CSV/XLSX). Si el nombre contiene 'Objetivo 1..6', se usa como etiqueta de fuente.")


